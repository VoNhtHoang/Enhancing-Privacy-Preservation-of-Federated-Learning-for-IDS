{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/hoang/FileCSV_DACN_2025/file1.csv', 'C:/Users/hoang/FileCSV_DACN_2025/file2.csv', 'C:/Users/hoang/FileCSV_DACN_2025/file3.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "input_files = [\"file1.csv\", \"file2.csv\", \"file3.csv\"]\n",
    "\n",
    "temp_dir = \"C:/Users/hoang/FileCSV_DACN_2025/\"  # Thư mục lưu file tạm\n",
    "\n",
    "input_files = [temp_dir + output_file for output_file in input_files]\n",
    "print(input_files)\n",
    "\n",
    "df = [dk.read_csv(input_file) for input_file in input_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "ratio_test_all = 0.15\n",
    "\n",
    "# from dask_ml.model_selection import train_test_split \n",
    "# # chia train test ratio 0.8:0.2 & random \n",
    "# train_df, test_df = train_test_split(df, test_size=ratio_test_all, random_state=42)\n",
    "\n",
    "def dask_to_tf_dataset(dask_df, batch_size=128, num_classes=10): \n",
    "    def generator():\n",
    "        for batch in dask_df.to_delayed():\n",
    "            batch=batch.compute()  \n",
    "            if batch.empty:\n",
    "                continue\n",
    "\n",
    "            X = batch.drop(columns='label').values.astype(np.float32)\n",
    "            y = batch['label'].values\n",
    "            y_onehot = to_categorical(y, num_classes=num_classes)  \n",
    "\n",
    "            num_splits = max(1, len(X) // batch_size)  # Đảm bảo không chia nhỏ quá mức\n",
    "            X_batches = np.array_split(X, num_splits)\n",
    "            y_batches = np.array_split(y_onehot, num_splits)\n",
    "\n",
    "            for X_batch, y_batch in zip(X_batches, y_batches):\n",
    "                yield X_batch, y_batch\n",
    "                \n",
    "    output_signature = ( \n",
    "        tf.TensorSpec(shape=(None, 46), dtype=tf.float32), \n",
    "        tf.TensorSpec(shape=(None, 10), dtype=tf.int32),\n",
    "    )\n",
    "    \n",
    "    return tf.data.Dataset.from_generator(generator, output_signature=output_signature).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df1, test_df1 = df1.random_split([1 - ratio_test_all, ratio_test_all])\n",
    "# train_df2, test_df2 = df2.random_split([1 - ratio_test_all, ratio_test_all])\n",
    "# train_df3, test_df3 = df3.random_split([1 - ratio_test_all, ratio_test_all])\n",
    "train_dfs = []\n",
    "test_dfs = []\n",
    "for dff in df:\n",
    "    train_df, test_df =dff.random_split([1 - ratio_test_all, ratio_test_all])\n",
    "    train_dfs.append(train_df)\n",
    "    test_dfs.append(test_df)\n",
    "   \n",
    "\n",
    "# train_gen1 = dask_to_tf_dataset(train_df1, 512, 10).repeat()\n",
    "# train_gen2 = dask_to_tf_dataset(train_df2, 512, 10).repeat()\n",
    "# train_gen3 = dask_to_tf_dataset(train_df3, 512, 10).repeat()\n",
    "train_gens = [dask_to_tf_dataset(train_df, 512, 10).repeat() for train_df in train_dfs]\n",
    "\n",
    "# test_gen1 = dask_to_tf_dataset(test_df1, 512, 10).repeat()\n",
    "# test_gen2 = dask_to_tf_dataset(test_df2, 512, 10).repeat()\n",
    "# test_gen3 = dask_to_tf_dataset(test_df3, 512, 10).repeat()\n",
    "test_gens = [dask_to_tf_dataset(test_df , 512, 10).repeat() for test_df in test_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['server_0']\n",
      "['client_0', 'client_1', 'client_2']\n",
      "Agent_Dict:  <client.Client object at 0x000002D6375909D0>\n",
      "<server.Server object at 0x000002D63726D450>\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "from server import Server\n",
    "from client import Client\n",
    "num_servers = 1\n",
    "num_clients = 3\n",
    "\n",
    "active_servers_list  = ['server_'+str(i)\\\n",
    "                        for i in range(num_servers)]\n",
    "active_clients_list  = ['client_'+str(i)\\\n",
    "                        for i in range(num_clients)]\n",
    "\n",
    "print(active_servers_list)\n",
    "print(active_clients_list)\n",
    "\n",
    "agents_dict= {}\n",
    "serverObjects={}\n",
    "clientObjects={}\n",
    "serverObjects = {server_name: Server(server_name=server_name, \\\n",
    "                        active_clients_list=active_clients_list) \\\n",
    "                        for server_name in active_servers_list}\n",
    "\n",
    "clientObjects = {client_name: Client(client_name, train_gens[clientID], test_gens[clientID], \\\n",
    "                        active_clients_list = active_clients_list) \\\n",
    "                        for clientID, client_name in enumerate(active_clients_list)}\n",
    "\n",
    "# lưu dict\n",
    "agents_dict['server'] = serverObjects\n",
    "agents_dict['client'] = clientObjects\n",
    "\n",
    "# init agents_dict vừa tạo vào client, server\n",
    "for agent_name, agent in serverObjects.items():\n",
    "    agent.set_agentsDict(agents_dict=agents_dict)\n",
    "for agent_name, agent in clientObjects.items():\n",
    "    agent.set_agentsDict(agents_dict=agents_dict)\n",
    "\n",
    "client_name = 'client_1'\n",
    "print(\"Agent_Dict: \", agents_dict['client'][client_name])\n",
    "\n",
    "server = agents_dict['server']['server_0']\n",
    "print(server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= Đang chạy Iteration 1=============================\n",
      "Input Shape: (46, 1)\n",
      "Input Shape: (46, 1)\n",
      "Epoch 1/5\n",
      "Input Shape: (46, 1)\n",
      "Epoch 1/5\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    server.InitLoop()\n",
    "    server.final_statistics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
