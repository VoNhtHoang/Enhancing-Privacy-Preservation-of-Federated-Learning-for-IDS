{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "file_path = \"Processed_Data/Mapped_Dataset.csv\"\n",
    "\n",
    "df = dk.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global var \n",
    "batch_size = 512\n",
    "ratio_test_all = 0.15\n",
    "\n",
    "from dask_ml.model_selection import train_test_split \n",
    "# chia train test ratio 0.8:0.2 & random \n",
    "train_df, test_df = train_test_split(df, test_size=ratio_test_all, random_state=42)\n",
    "\n",
    "# # load từng batch\n",
    "def dask_to_tf_dataset(dask_df, batch_size=128, num_classes=10): \n",
    "    def generator():\n",
    "        for batch in dask_df.to_delayed():\n",
    "            batch=batch.compute()  \n",
    "            if batch.empty:\n",
    "                continue\n",
    "\n",
    "            X = batch.drop(columns='label').values.astype(np.float32)\n",
    "            y = batch['label'].values\n",
    "            y_onehot = to_categorical(y, num_classes=num_classes)  \n",
    "\n",
    "            num_splits = max(1, len(X) // batch_size)  # Đảm bảo không chia nhỏ quá mức\n",
    "            X_batches = np.array_split(X, num_splits)\n",
    "            y_batches = np.array_split(y_onehot, num_splits)\n",
    "\n",
    "            for X_batch, y_batch in zip(X_batches, y_batches):\n",
    "                yield X_batch, y_batch\n",
    "                \n",
    "    output_signature = ( \n",
    "        tf.TensorSpec(shape=(None, 46), dtype=tf.float32), \n",
    "        tf.TensorSpec(shape=(None, 10), dtype=tf.int32),\n",
    "    )\n",
    "    \n",
    "    return tf.data.Dataset.from_generator(generator, output_signature=output_signature).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = dask_to_tf_dataset(train_df, 512, 10).repeat()\n",
    "test_gen = dask_to_tf_dataset(test_df, 512, 10).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfhe import *\n",
    "\n",
    "# Khởi tạo context BFV (hỗ trợ số nguyên) hoặc CKKS (hỗ trợ số thực)\n",
    "def create_fhe_context():\n",
    "    context = CryptoContextFactory.default_context()\n",
    "    context.Enable(PKESchemeFeature.ENCRYPTION)\n",
    "    context.Enable(PKESchemeFeature.SHE)  # Hỗ trợ phép nhân & cộng\n",
    "    return context\n",
    "\n",
    "context = create_fhe_context()\n",
    "keys = context.KeyGen()\n",
    "\n",
    "def encrypt_data(context, data):\n",
    "    encrypted = []\n",
    "    for sample in data:  # Lặp qua từng mẫu trong batch\n",
    "        encrypted.append(context.Encrypt(keys.publicKey, context.MakeCKKSPackedPlaintext(sample.tolist())))\n",
    "    return encrypted\n",
    "\n",
    "def decrypt_data(context, encrypted_data):\n",
    "    decrypted = []\n",
    "    for enc in encrypted_data:\n",
    "        decrypted.append(enc.Decrypt(keys.secretKey).GetPackedValue())\n",
    "    return decrypted\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Mô hình suy luận đơn giản bằng Fully Connected trên dữ liệu mã hóa\n",
    "class EncryptedModel:\n",
    "    def __init__(self, context):\n",
    "        self.context = context\n",
    "        self.weights = context.MakeCKKSPackedPlaintext(np.random.rand(128).tolist())  # Trọng số giả lập\n",
    "        self.bias = context.MakeCKKSPackedPlaintext(np.random.rand(128).tolist())   #CKKS cho số thực\n",
    "\n",
    "\n",
    "    def forward(self, encrypted_input):\n",
    "        encrypted_output = encrypted_input * self.weights + self.bias\n",
    "        return encrypted_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# shape\n",
    "features, labels = next(iter(train_gen))\n",
    "input_shape = (features.shape[1], 1)\n",
    "output_shape = labels.shape[1]\n",
    "\n",
    "print(f\"Input Shape: {input_shape}\")\n",
    "\n",
    "from tensorflow import keras\n",
    "# Định nghĩa mô hình CNN\n",
    "# VGG, ...\n",
    "# Conv2D, tabular, ...\n",
    "# HE, tính tương thích của HE với CNN\n",
    "# Tính chất data in, out; Học tăng cường\n",
    "\n",
    "# matplotlib để xuất kết quả; xuất thêm log, bắt đầu chia client để test \n",
    "# độ chính xác, loss, độ hội tụ: có DP, có HE, không có. set nhiều gtri differetial privacy để đánh giá\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv1D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling1D(pool_size=4),\n",
    "    layers.Conv1D(filters=64, kernel_size=3,  padding=\"same\",activation=\"relu\"),\n",
    "    layers.MaxPooling1D(pool_size=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(output_shape, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# for batch in dataloader:\n",
    "#     X_batch = batch[:, :-1]\n",
    "#     y_batch = batch[:, -1]\n",
    "#     y_onehot = to_categorical(y_batch, num_classes=10)\n",
    "    \n",
    "#     model.train_on_batch(X_batch, y_onehot, verbose=1)\n",
    "model.fit(train_gen, epochs=10, steps_per_epoch=71000, verbose = 1)\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save(\"cnn_model_2-0_batch512_test015.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load model từ file .h5\n",
    "model = load_model(\"cnn_model_2-0_batch512_test015.h5\")\n",
    "\n",
    "# Test với dữ liệu đầu vào\n",
    "import numpy as np\n",
    "output = model.evaluate(test_gen, steps= 190000)\n",
    "print(f'Loss: {output[1]} Acc: {output[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mã hóa dữ liệu test\n",
    "encrypted_X_batch = encrypt_data(context, X_batch)\n",
    "\n",
    "# Suy luận trên dữ liệu mã hóa\n",
    "encrypted_model = EncryptedModel(context)\n",
    "encrypted_output = encrypted_model.forward(encrypted_X_batch)\n",
    "\n",
    "# Giải mã kết quả\n",
    "decrypted_output = decrypt_data(context, encrypted_output)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
